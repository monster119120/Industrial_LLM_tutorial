# Native Sparse Attention

本文简要介绍Native Sparse Attention (NSA) 的原理。

## 标准Self Attention计算流程

![normal_attention](https://github.com/monster119120/Industrial_LLM_tutorial/raw/main/2_training/algo/nsa/normal_attention.png)


## Native Sparse Attention (NSA) 的计算流程

![nsa_total](https://github.com/monster119120/Industrial_LLM_tutorial/raw/main/2_training/algo/nsa/nsa_total.png)

![compress_attention](https://github.com/monster119120/Industrial_LLM_tutorial/raw/main/2_training/algo/nsa/compress_attention.png)


![top_n_attention](https://github.com/monster119120/Industrial_LLM_tutorial/raw/main/2_training/algo/nsa/top_n_attention.png)


![sliding_window_attention](https://github.com/monster119120/Industrial_LLM_tutorial/raw/main/2_training/algo/nsa/sliding_window_attention.png)
